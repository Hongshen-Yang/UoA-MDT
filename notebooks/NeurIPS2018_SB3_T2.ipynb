{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeurIPS2018_SB3\n",
    "\n",
    "This is a modification version based on the first notebook from [FinRL-tutorial](https://github.com/AI4Finance-Foundation/FinRL-Tutorials)\n",
    "\n",
    "https://github.com/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/Stock_NeurIPS2018_SB3.ipynb\n",
    "\n",
    "## Part 1. Task Discription\n",
    "DRL agent training for cryptocurrency trading. \n",
    "\n",
    "This task is modeled as a Markov Decision Process (MDP), and the objective function is maximizing (expected) cumulative return.\n",
    "\n",
    "We specify the state-action-reward as follows:\n",
    "\n",
    "* **State s**: The states of the OHLCVT trading information consists of two co-moving assets (BTCUSD and BTCEUR).\n",
    "\n",
    "* **Action a**: The action space includes buying and selling. However, a certain limitation is included to operate on both assets. The pair shall never be actioned alone, it must come with a reversed direction.\n",
    "\n",
    "* **Reward function r(s, a, s′)**: Reward is an incentive for an agent to learn a better policy. For example, it can be the change of the portfolio value when taking a at state s and arriving at new state s', i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
    "\n",
    "**Market environment**: Cryptocurrencies from Binance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HSY/miniconda3/envs/uoa-mdt/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime, sqlite3, zipfile, os\n",
    "\n",
    "%matplotlib inline\n",
    "# from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from T2.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "check_and_make_directories([TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Read data from `binance-public-data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2017-08-17'\n",
    "TRAIN_END_DATE = '2022-12-31'\n",
    "TRADE_START_DATE = '2023-01-01'\n",
    "TRADE_END_DATE = '2023-07-31'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This is read from SQLite database\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('../sqlite.db')\n",
    "\n",
    "table_name = 'kline_copy'\n",
    "\n",
    "# Read data from the table into a DataFrame\n",
    "query = f'SELECT * FROM {table_name};'\n",
    "sql_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Create a new DataFrame with renamed columns\n",
    "df = sql_df[['start_time', 'open', 'high', 'low', 'close', 'base_vol', 'symbol', 'id']].rename(\n",
    "    columns={\n",
    "    'start_time': 'start_time',\n",
    "    'open': 'open',\n",
    "    'high': 'high',\n",
    "    'low': 'low',\n",
    "    'close': 'close',\n",
    "    'base_vol': 'volume',\n",
    "    'symbol': 'tic',\n",
    "    'id': 'id'\n",
    "    })\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>301.13</td>\n",
       "      <td>312.18</td>\n",
       "      <td>298.00</td>\n",
       "      <td>302.00</td>\n",
       "      <td>7030.710340</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>302.00</td>\n",
       "      <td>311.79</td>\n",
       "      <td>283.94</td>\n",
       "      <td>293.96</td>\n",
       "      <td>9537.846460</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>4184.69</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>4139.98</td>\n",
       "      <td>381.309763</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     open     high      low    close       volume      tic  day\n",
       "0  2017-08-17  4261.48  4485.39  4200.74  4285.08   795.150377  BTCUSDT    0\n",
       "1  2017-08-17   301.13   312.18   298.00   302.00  7030.710340  ETHUSDT    0\n",
       "2  2017-08-18  4285.08  4371.52  3938.77  4108.37  1199.888264  BTCUSDT    1\n",
       "3  2017-08-18   302.00   311.79   283.94   293.96  9537.846460  ETHUSDT    1\n",
       "4  2017-08-19  4108.37  4184.69  3850.00  4139.98   381.309763  BTCUSDT    2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of symbols to merge\n",
    "symbols = ['BTCUSDT', 'ETHUSDT']\n",
    "\n",
    "# List to store individual DataFrames\n",
    "rawdfs = []\n",
    "\n",
    "# Loop through each symbol\n",
    "for symbol in symbols:\n",
    "    directory = f'../mdt_utils/binance-public-data/python/data/spot/monthly/klines/{symbol}/1d/'\n",
    "    \n",
    "    # Loop through each zip file in the directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.zip'):\n",
    "            with zipfile.ZipFile(os.path.join(directory, file_name), 'r') as zip_ref:\n",
    "                # only one CSV file in each zip archive\n",
    "                csv_file = zip_ref.namelist()[0]\n",
    "                with zip_ref.open(csv_file) as csv_fp:\n",
    "                    # Read the CSV data into a DataFrame\n",
    "                    temp_df = pd.read_csv(csv_fp, header=None)\n",
    "                    temp_df.columns = ['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "                    temp_df['date'] = pd.to_datetime(temp_df['close_time'], unit='ms').dt.strftime('%Y-%m-%d')\n",
    "                    temp_df['day'] = (pd.to_datetime(temp_df['date']) - pd.to_datetime(temp_df['date'].iloc[0])).dt.days\n",
    "                    temp_df['tic'] = symbol\n",
    "                    rawdfs.append(temp_df[['date', 'open', 'high', 'low', 'close', 'volume', 'tic', 'day']])\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "rawdf = pd.concat(rawdfs, ignore_index=True)\n",
    "\n",
    "# Count the number of unique 'tic' values per date\n",
    "tic_counts = rawdf.groupby('date')['tic'].nunique()\n",
    "\n",
    "# Filter the DataFrame to keep only rows where all 'tic' values participate\n",
    "df = rawdf[rawdf['date'].isin(tic_counts[tic_counts == len(rawdf['tic'].unique())].index)]\n",
    "\n",
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Preprocess Data\n",
    "\n",
    "TODO: The default feature engineering is based on date. I need to rewrite into timestamp based method\n",
    "\n",
    "The dafult [data split](https://github.com/AI4Finance-Foundation/FinRL/blob/master/finrl/meta/preprocessor/preprocessors.py) is not applicable here. Need to manually redo it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (1496, 8)\n",
      "Successfully added vix\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = INDICATORS,\n",
    "                    use_vix=True,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4446.630679</td>\n",
       "      <td>3946.819321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4285.080</td>\n",
       "      <td>4285.080</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>301.13</td>\n",
       "      <td>312.18</td>\n",
       "      <td>298.00</td>\n",
       "      <td>302.00</td>\n",
       "      <td>7030.710340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4446.630679</td>\n",
       "      <td>3946.819321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>302.000</td>\n",
       "      <td>302.000</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.964647</td>\n",
       "      <td>4446.630679</td>\n",
       "      <td>3946.819321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4196.725</td>\n",
       "      <td>4196.725</td>\n",
       "      <td>14.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>302.00</td>\n",
       "      <td>311.79</td>\n",
       "      <td>283.94</td>\n",
       "      <td>293.96</td>\n",
       "      <td>9537.846460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.180385</td>\n",
       "      <td>309.350277</td>\n",
       "      <td>286.609723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>297.980</td>\n",
       "      <td>297.980</td>\n",
       "      <td>14.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>4069.13</td>\n",
       "      <td>4119.62</td>\n",
       "      <td>3911.79</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>691.743060</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.655882</td>\n",
       "      <td>4325.847407</td>\n",
       "      <td>3928.440593</td>\n",
       "      <td>9.487016</td>\n",
       "      <td>-92.693236</td>\n",
       "      <td>88.718699</td>\n",
       "      <td>4127.144</td>\n",
       "      <td>4127.144</td>\n",
       "      <td>13.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      tic     open     high      low    close       volume  day  \\\n",
       "0  2017-08-17  BTCUSDT  4261.48  4485.39  4200.74  4285.08   795.150377  0.0   \n",
       "1  2017-08-17  ETHUSDT   301.13   312.18   298.00   302.00  7030.710340  0.0   \n",
       "2  2017-08-18  BTCUSDT  4285.08  4371.52  3938.77  4108.37  1199.888264  1.0   \n",
       "3  2017-08-18  ETHUSDT   302.00   311.79   283.94   293.96  9537.846460  1.0   \n",
       "4  2017-08-21  BTCUSDT  4069.13  4119.62  3911.79  4016.00   691.743060  4.0   \n",
       "\n",
       "       macd      boll_ub      boll_lb    rsi_30     cci_30       dx_30  \\\n",
       "0  0.000000  4446.630679  3946.819321  0.000000 -66.666667  100.000000   \n",
       "1  0.000000  4446.630679  3946.819321  0.000000 -66.666667  100.000000   \n",
       "2 -3.964647  4446.630679  3946.819321  0.000000 -66.666667  100.000000   \n",
       "3 -0.180385   309.350277   286.609723  0.000000 -66.666667  100.000000   \n",
       "4 -9.655882  4325.847407  3928.440593  9.487016 -92.693236   88.718699   \n",
       "\n",
       "   close_30_sma  close_60_sma    vix  \n",
       "0      4285.080      4285.080  15.55  \n",
       "1       302.000       302.000  15.55  \n",
       "2      4196.725      4196.725  14.26  \n",
       "3       297.980       297.980  14.26  \n",
       "4      4127.144      4127.144  13.19  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Build A Market Environment in OpenAI Gym-style\n",
    "The training process involves observing cryptocurrency price change, taking an action and reward's calculation. By interacting with the market environment, the agent will eventually derive a trading strategy that may maximize (expected) rewards.\n",
    "\n",
    "Our market environment, based on OpenAI Gym, simulates stock markets with historical market data.\n",
    "\n",
    "### Data Split\n",
    "We split the data into training set and testing set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data length: 2706\n",
      "Trade Data Length: 286\n",
      "Indicators: ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE, TRADE_END_DATE)\n",
    "train_length = len(train)\n",
    "trade_length = len(trade)\n",
    "print(f\"Training Data length: {train_length}\")\n",
    "print(f\"Trade Data Length: {trade_length}\")\n",
    "print(f\"Indicators: {INDICATORS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are trading with 2 assets as a pair, therefore we have only 1 pair_dimension\n",
    "\n",
    "> `1`: Represents the cash balance. There's one element in the state for the agent's cash.\n",
    ">\n",
    "> `2 * stock_dimension`: Represents the stock prices and stock ownership. There are two elements for each stock: one for the stock price and one for the number of shares owned.\n",
    ">\n",
    "> `len(INDICATORS) * stock_dimension`: Represents the technical indicators for each stock. Each indicator contributes one element per stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock Dimension: 2, State Space: 21\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "if stock_dimension != 2:\n",
    "    raise ValueError(\"Stock dimension must be equal to 2 for pair trading.\")\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 1, # int, maximum number of coins to trade\n",
    "    \"initial_amount\": 100000, # start with 1000000 USDT\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list, # transaction cost percentage per trade\n",
    "    \"sell_cost_pct\": sell_cost_list, # transaction cost percentage per trade\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": 2, # we will always have 2 stocks\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": 2, # we only allow the trade to give a single action\n",
    "    \"reward_scaling\": 1e-4 # scaling factor for reward, good for training\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of state\n",
    "```\n",
    "94502.19235000112: This is the available cash balance that the agent has for making trading decisions.\n",
    "24948.21: The price of the first stock in your trading pair (e.g., BTC-GBP).\n",
    "21668.05: The price of the second stock in your trading pair (e.g., BTC-EUR).\n",
    "103: The number of shares the agent holds for the first stock (e.g., BTC-GBP).\n",
    "0: The number of shares the agent holds for the second stock (e.g., BTC-EUR).\n",
    "-299.9631790789099: A technical indicator value.\n",
    "-345.112034646816: A technical indicator value.\n",
    "26817.756609157783: A technical indicator value.\n",
    "23644.528099789444: A technical indicator value.\n",
    "24186.333390842214: A technical indicator value.\n",
    "20930.97290021056: A technical indicator value.\n",
    "48.63796032144048: A technical indicator value.\n",
    "47.40677058214158: A technical indicator value.\n",
    "-74.29641721884254: A technical indicator value.\n",
    "-89.66529346827706: A technical indicator value.\n",
    "12.572876815282788: A technical indicator value.\n",
    "16.60796108870377: A technical indicator value.\n",
    "25597.621333333333: A technical indicator value.\n",
    "22452.637666666666: A technical indicator value.\n",
    "25993.954166666666: A technical indicator value.\n",
    "22842.914500000003: A technical indicator value.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100000,\n",
       " 4285.08,\n",
       " 302.0,\n",
       " 0,\n",
       " 0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4446.630678606951,\n",
       " 4446.630678606951,\n",
       " 3946.81932139305,\n",
       " 3946.81932139305,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -66.666666666667,\n",
       " -66.666666666667,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 4285.08,\n",
       " 302.0,\n",
       " 4285.08,\n",
       " 302.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6. Train DRL Agents\n",
    "* The DRL algorithms are from Stable Baselines 3. Users are also encouraged to try ElegantRL and Ray RLlib.\n",
    "* FinRL includes fine-tuned standard DRL algorithms, such as DQN, DDPG, Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to results/a2c\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 722      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | -23      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.584    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.154    |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 760         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.94       |\n",
      "|    explained_variance | -0.231      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 0.812       |\n",
      "|    reward             | -0.14691672 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 691        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.95      |\n",
      "|    explained_variance | 0.067      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -0.781     |\n",
      "|    reward             | 0.22217578 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.113      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 720        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.96      |\n",
      "|    explained_variance | -0.161     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -3.74      |\n",
      "|    reward             | -0.7531018 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 2.68       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 740       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.96     |\n",
      "|    explained_variance | 0.0662    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 16.7      |\n",
      "|    reward             | 4.8155503 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 49.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 753         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.97       |\n",
      "|    explained_variance | -3.35       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -0.053      |\n",
      "|    reward             | -0.02276705 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.0196      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 762          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3           |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.0867      |\n",
      "|    reward             | -0.028306445 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.0013       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3          |\n",
      "|    explained_variance | -0.408      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.296       |\n",
      "|    reward             | -0.42442262 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.0496      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 778          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.01        |\n",
      "|    explained_variance | -0.154       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 4.34         |\n",
      "|    reward             | -0.046069205 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 2.5          |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 769        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.02      |\n",
      "|    explained_variance | 0.0732     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 0.852      |\n",
      "|    reward             | -0.9540041 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.837      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 758         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.04       |\n",
      "|    explained_variance | -0.618      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.247      |\n",
      "|    reward             | 0.011068515 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.0257      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 765       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.05     |\n",
      "|    explained_variance | 0.555     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -0.27     |\n",
      "|    reward             | 0.4142707 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.0113    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 771         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.05       |\n",
      "|    explained_variance | -0.817      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -10.1       |\n",
      "|    reward             | -0.22012651 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 10.7        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 776          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.06        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.17         |\n",
      "|    reward             | -0.023581315 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.00895      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 781        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.09      |\n",
      "|    explained_variance | -0.0343    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -0.0815    |\n",
      "|    reward             | 0.06194723 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.00102    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 777        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.11      |\n",
      "|    explained_variance | 0.218      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 0.363      |\n",
      "|    reward             | 0.09206127 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.0316     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 737          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.13        |\n",
      "|    explained_variance | -22.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.0651       |\n",
      "|    reward             | -0.008848154 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 0.00401      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 699        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.15      |\n",
      "|    explained_variance | -0.1       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 1.37       |\n",
      "|    reward             | 0.13681723 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 0.645      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 697      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 0.492    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.0135  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.59e-05 |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 698          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.16        |\n",
      "|    explained_variance | -0.00955     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.847       |\n",
      "|    reward             | -0.010346174 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 0.0624       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 702        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.16      |\n",
      "|    explained_variance | -0.212     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | -1.56      |\n",
      "|    reward             | -1.7961789 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 0.284      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 705         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.18       |\n",
      "|    explained_variance | -0.0194     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 5.61        |\n",
      "|    reward             | -0.26503754 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 4.55        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 709        |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.2       |\n",
      "|    explained_variance | 0.275      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -0.847     |\n",
      "|    reward             | 0.43640494 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 0.2        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 714        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.19      |\n",
      "|    explained_variance | -0.0343    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | -13.1      |\n",
      "|    reward             | -0.1581501 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 34.2       |\n",
      "--------------------------------------\n",
      "day: 1352, episode: 10\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 417694.77\n",
      "total_reward: 317694.77\n",
      "total_cost: 3522.30\n",
      "total_trades: 5408\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 698        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.18      |\n",
      "|    explained_variance | 0.0409     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | -2.78      |\n",
      "|    reward             | 0.29979783 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 0.655      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 697        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.18      |\n",
      "|    explained_variance | -0.0129    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 2          |\n",
      "|    reward             | -0.2428251 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 0.573      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 701        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.17      |\n",
      "|    explained_variance | 0.304      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -6.41      |\n",
      "|    reward             | 0.03438371 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 4.96       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 703        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.19      |\n",
      "|    explained_variance | 0.24       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | 8.35       |\n",
      "|    reward             | 0.33246893 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 6.89       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 704       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.2      |\n",
      "|    explained_variance | -0.0178   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | -4.143793 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 19.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 703         |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.22       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -0.022      |\n",
      "|    reward             | -0.09598101 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 0.000401    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 699         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.24       |\n",
      "|    explained_variance | 0.184       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -0.629      |\n",
      "|    reward             | -0.17064168 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 0.09        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 702        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.24      |\n",
      "|    explained_variance | -0.168     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -3.78      |\n",
      "|    reward             | 0.34150034 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 0.946      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 703        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 0.157      |\n",
      "|    reward             | -0.0589398 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 0.00222    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 706        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | -0.56      |\n",
      "|    reward             | 0.13396803 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 0.117      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 709        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.27      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | -2.41      |\n",
      "|    reward             | 0.20629515 |\n",
      "|    std                | 1.24       |\n",
      "|    value_loss         | 0.904      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 712      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.0546   |\n",
      "|    reward             | 0.023195 |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 0.000218 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 715       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.34     |\n",
      "|    explained_variance | 0.185     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -1.44     |\n",
      "|    reward             | -0.002011 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 0.228     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 717      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.0212  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 4.89e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 720       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.38     |\n",
      "|    explained_variance | -1.59e+04 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 0.0342    |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.31      |\n",
      "|    value_loss         | 0.000255  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.43    |\n",
      "|    explained_variance | -172     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.0335   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.35     |\n",
      "|    value_loss         | 0.000421 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 724      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.0132   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.39     |\n",
      "|    value_loss         | 1.18e-05 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.58    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.00164 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.45     |\n",
      "|    value_loss         | 2.62e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 722      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.00578 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 3.37e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.76    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.00458 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.58     |\n",
      "|    value_loss         | 1.71e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 721      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.87    |\n",
      "|    explained_variance | -29.6    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.00688 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.68     |\n",
      "|    value_loss         | 0.000124 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 721       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.97     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -0.000752 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.76      |\n",
      "|    value_loss         | 5.69e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 722       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -0.000526 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.86      |\n",
      "|    value_loss         | 2.4e-08   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 723      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.0233  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.98     |\n",
      "|    value_loss         | 3.67e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 722       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.3      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -0.000641 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 2.08      |\n",
      "|    value_loss         | 1.84e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 724      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.41    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.000107 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.2      |\n",
      "|    value_loss         | 5.7e-10  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 726      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.52    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.00853 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.32     |\n",
      "|    value_loss         | 2.34e-06 |\n",
      "------------------------------------\n",
      "day: 1352, episode: 20\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 98902.89\n",
      "total_reward: -1097.11\n",
      "total_cost: 17.88\n",
      "total_trades: 5408\n",
      "Sharpe: -0.088\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 720           |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 36            |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.58         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | 0.00331       |\n",
      "|    reward             | -9.187235e-05 |\n",
      "|    std                | 2.39          |\n",
      "|    value_loss         | 5.16e-07      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 721        |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.63      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | -0.0595    |\n",
      "|    reward             | 0.11117334 |\n",
      "|    std                | 2.44       |\n",
      "|    value_loss         | 0.000981   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 723          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.61        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | 1.03         |\n",
      "|    reward             | -0.072612815 |\n",
      "|    std                | 2.42         |\n",
      "|    value_loss         | 0.0556       |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 724      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -0.00214 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.46     |\n",
      "|    value_loss         | 1.79e-07 |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 726           |\n",
      "|    iterations         | 5600          |\n",
      "|    time_elapsed       | 38            |\n",
      "|    total_timesteps    | 28000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.68         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5599          |\n",
      "|    policy_loss        | -0.0257       |\n",
      "|    reward             | -0.0010513263 |\n",
      "|    std                | 2.52          |\n",
      "|    value_loss         | 0.00242       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 712         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.72       |\n",
      "|    explained_variance | -0.227      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | 0.355       |\n",
      "|    reward             | 0.004559833 |\n",
      "|    std                | 2.56        |\n",
      "|    value_loss         | 0.00789     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 707          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.77        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | 0.0136       |\n",
      "|    reward             | -0.021463297 |\n",
      "|    std                | 2.63         |\n",
      "|    value_loss         | 2.83e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 708        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.79      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -5.88      |\n",
      "|    reward             | -0.8704792 |\n",
      "|    std                | 2.65       |\n",
      "|    value_loss         | 1.92       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 710      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.8     |\n",
      "|    explained_variance | -19.1    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -0.125   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.67     |\n",
      "|    value_loss         | 0.000645 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.84    |\n",
      "|    explained_variance | 1.25e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 0.00278  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 3.59e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 713      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.89    |\n",
      "|    explained_variance | -246     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -0.026   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.8      |\n",
      "|    value_loss         | 5.68e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 711      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.000365 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.91     |\n",
      "|    value_loss         | 7.08e-09 |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 713         |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | 0.0846      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | 4.69        |\n",
      "|    reward             | -0.19379506 |\n",
      "|    std                | 2.98        |\n",
      "|    value_loss         | 3.29        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 714      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.01    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.00702  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.97     |\n",
      "|    value_loss         | 2.1e-06  |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 716         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | 0.208       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.182      |\n",
      "|    reward             | -0.24060829 |\n",
      "|    std                | 3.03        |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 718        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.08      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | -8.31      |\n",
      "|    reward             | -0.2520449 |\n",
      "|    std                | 3.07       |\n",
      "|    value_loss         | 3.63       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 719      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | -0.0289  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.12     |\n",
      "|    value_loss         | 4.01e-05 |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 720         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.14       |\n",
      "|    explained_variance | 0.182       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 0.213       |\n",
      "|    reward             | 0.013451921 |\n",
      "|    std                | 3.17        |\n",
      "|    value_loss         | 0.0177      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 721        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | -19.8      |\n",
      "|    reward             | 0.62417954 |\n",
      "|    std                | 3.21       |\n",
      "|    value_loss         | 19.4       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 723      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -0.0237  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.24     |\n",
      "|    value_loss         | 1.71e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 724       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -0.000166 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 3.3       |\n",
      "|    value_loss         | 1.22e-09  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 725         |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.25       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -10.4       |\n",
      "|    reward             | -0.19362137 |\n",
      "|    std                | 3.35        |\n",
      "|    value_loss         | 4.84        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 726         |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.27       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | 2.82        |\n",
      "|    reward             | -0.62525964 |\n",
      "|    std                | 3.37        |\n",
      "|    value_loss         | 0.321       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 728        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.29      |\n",
      "|    explained_variance | 0.0515     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | -1.02      |\n",
      "|    reward             | 0.42913285 |\n",
      "|    std                | 3.41       |\n",
      "|    value_loss         | 0.46       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 729         |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.28       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | -0.215      |\n",
      "|    reward             | -0.09167012 |\n",
      "|    std                | 3.39        |\n",
      "|    value_loss         | 0.00817     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 730        |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.3       |\n",
      "|    explained_variance | -2.92      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -4.05      |\n",
      "|    reward             | 0.31949008 |\n",
      "|    std                | 3.42       |\n",
      "|    value_loss         | 0.544      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 731       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.32     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 3.74      |\n",
      "|    reward             | 0.2737993 |\n",
      "|    std                | 3.46      |\n",
      "|    value_loss         | 1.57      |\n",
      "-------------------------------------\n",
      "day: 1352, episode: 30\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 371165.23\n",
      "total_reward: 271165.23\n",
      "total_cost: 66.76\n",
      "total_trades: 5408\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 732        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.34      |\n",
      "|    explained_variance | -0.368     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 1.47       |\n",
      "|    reward             | 0.27786043 |\n",
      "|    std                | 3.49       |\n",
      "|    value_loss         | 0.101      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 733         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.35       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 1.25        |\n",
      "|    reward             | 0.111317724 |\n",
      "|    std                | 3.51        |\n",
      "|    value_loss         | 0.0618      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.37       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | -1.96       |\n",
      "|    reward             | -0.07552685 |\n",
      "|    std                | 3.55        |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 734         |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.39       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | 0.221       |\n",
      "|    reward             | 0.043309502 |\n",
      "|    std                | 3.59        |\n",
      "|    value_loss         | 0.00207     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 734            |\n",
      "|    iterations         | 8300           |\n",
      "|    time_elapsed       | 56             |\n",
      "|    total_timesteps    | 41500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.4           |\n",
      "|    explained_variance | 0.135          |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8299           |\n",
      "|    policy_loss        | -10.9          |\n",
      "|    reward             | -0.00087746076 |\n",
      "|    std                | 3.61           |\n",
      "|    value_loss         | 4.4            |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 735        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 57         |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.44      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 1.23       |\n",
      "|    reward             | 0.04203522 |\n",
      "|    std                | 3.66       |\n",
      "|    value_loss         | 0.0666     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 736        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 57         |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.45      |\n",
      "|    explained_variance | 0.027      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 13.9       |\n",
      "|    reward             | 0.33067122 |\n",
      "|    std                | 3.68       |\n",
      "|    value_loss         | 6.91       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 733       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.47     |\n",
      "|    explained_variance | -0.0187   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -0.143    |\n",
      "|    reward             | 3.7493126 |\n",
      "|    std                | 3.73      |\n",
      "|    value_loss         | 26.1      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 732         |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.47       |\n",
      "|    explained_variance | 0.435       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8699        |\n",
      "|    policy_loss        | -0.0282     |\n",
      "|    reward             | -0.31684458 |\n",
      "|    std                | 3.73        |\n",
      "|    value_loss         | 0.00089     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 731        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.47      |\n",
      "|    explained_variance | -0.0522    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 1.01       |\n",
      "|    reward             | -0.1497792 |\n",
      "|    std                | 3.74       |\n",
      "|    value_loss         | 0.0846     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 727       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.46     |\n",
      "|    explained_variance | -0.000447 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -3.13     |\n",
      "|    reward             | 2.4090571 |\n",
      "|    std                | 3.72      |\n",
      "|    value_loss         | 0.555     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 727        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.48      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 0.0311     |\n",
      "|    reward             | -0.1497729 |\n",
      "|    std                | 3.74       |\n",
      "|    value_loss         | 0.00185    |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 728      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.49    |\n",
      "|    explained_variance | -1.12    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 23.8     |\n",
      "|    reward             | 2.081238 |\n",
      "|    std                | 3.76     |\n",
      "|    value_loss         | 17.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 728       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -0.804    |\n",
      "|    reward             | 0.076102  |\n",
      "|    std                | 3.76      |\n",
      "|    value_loss         | 0.232     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 728          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.5         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | 0.426        |\n",
      "|    reward             | -0.041200265 |\n",
      "|    std                | 3.78         |\n",
      "|    value_loss         | 0.00797      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 729       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.5      |\n",
      "|    explained_variance | 0.0944    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 13.4      |\n",
      "|    reward             | 1.0307671 |\n",
      "|    std                | 3.79      |\n",
      "|    value_loss         | 13.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 729         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 65          |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.5        |\n",
      "|    explained_variance | -0.199      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -6.35       |\n",
      "|    reward             | 0.015300463 |\n",
      "|    std                | 3.78        |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 729        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.5       |\n",
      "|    explained_variance | 0.000905   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 1.08       |\n",
      "|    reward             | -2.9705684 |\n",
      "|    std                | 3.79       |\n",
      "|    value_loss         | 0.0476     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 728       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.49     |\n",
      "|    explained_variance | 0.0103    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 14.9      |\n",
      "|    reward             | -0.708565 |\n",
      "|    std                | 3.77      |\n",
      "|    value_loss         | 7.8       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 729        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.49      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | 0.392      |\n",
      "|    reward             | 0.18840584 |\n",
      "|    std                | 3.77       |\n",
      "|    value_loss         | 0.00494    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 730        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.5       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | -1.01      |\n",
      "|    reward             | 0.13205995 |\n",
      "|    std                | 3.78       |\n",
      "|    value_loss         | 0.0327     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 731          |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.51        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | 1.34         |\n",
      "|    reward             | -0.029844737 |\n",
      "|    std                | 3.8          |\n",
      "|    value_loss         | 0.165        |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1352, episode: 40\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 213608.12\n",
      "total_reward: 113608.12\n",
      "total_cost: 99.89\n",
      "total_trades: 5408\n",
      "Sharpe: 0.623\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 207      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 5412     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 159      |\n",
      "|    critic_loss     | 665      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4059     |\n",
      "|    reward          | -0.0089  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 176      |\n",
      "|    time_elapsed    | 61       |\n",
      "|    total_timesteps | 10824    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 114      |\n",
      "|    critic_loss     | 240      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9471     |\n",
      "|    reward          | -0.0089  |\n",
      "---------------------------------\n",
      "day: 1352, episode: 50\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 213608.12\n",
      "total_reward: 113608.12\n",
      "total_cost: 99.89\n",
      "total_trades: 5408\n",
      "Sharpe: 0.623\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 171      |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total_timesteps | 16236    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 87.2     |\n",
      "|    critic_loss     | 72.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14883    |\n",
      "|    reward          | -0.0089  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 172      |\n",
      "|    time_elapsed    | 125      |\n",
      "|    total_timesteps | 21648    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 57.5     |\n",
      "|    critic_loss     | 18.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20295    |\n",
      "|    reward          | -0.0089  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 174      |\n",
      "|    time_elapsed    | 155      |\n",
      "|    total_timesteps | 27060    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 35.7     |\n",
      "|    critic_loss     | 4.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25707    |\n",
      "|    reward          | -0.0089  |\n",
      "---------------------------------\n",
      "day: 1352, episode: 60\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 213608.12\n",
      "total_reward: 113608.12\n",
      "total_cost: 99.89\n",
      "total_trades: 5408\n",
      "Sharpe: 0.623\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 174      |\n",
      "|    time_elapsed    | 185      |\n",
      "|    total_timesteps | 32472    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 26.1     |\n",
      "|    critic_loss     | 2.66     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31119    |\n",
      "|    reward          | -0.0089  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 173      |\n",
      "|    time_elapsed    | 217      |\n",
      "|    total_timesteps | 37884    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 19.3     |\n",
      "|    critic_loss     | 1.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36531    |\n",
      "|    reward          | -0.0089  |\n",
      "---------------------------------\n",
      "day: 1352, episode: 70\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 213608.12\n",
      "total_reward: 113608.12\n",
      "total_cost: 99.89\n",
      "total_trades: 5408\n",
      "Sharpe: 0.623\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 173      |\n",
      "|    time_elapsed    | 249      |\n",
      "|    total_timesteps | 43296    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 14.3     |\n",
      "|    critic_loss     | 0.691    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41943    |\n",
      "|    reward          | -0.0089  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 172      |\n",
      "|    time_elapsed    | 282      |\n",
      "|    total_timesteps | 48708    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 10.8     |\n",
      "|    critic_loss     | 0.654    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 47355    |\n",
      "|    reward          | -0.0089  |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 1143        |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 1           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.052152406 |\n",
      "------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1071          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0057544857  |\n",
      "|    clip_fraction        | 0.0227        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 0.0539        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 1.09          |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00212      |\n",
      "|    reward               | -0.0002352681 |\n",
      "|    std                  | 0.994         |\n",
      "|    value_loss           | 4.4           |\n",
      "-------------------------------------------\n",
      "day: 1352, episode: 80\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 176845.69\n",
      "total_reward: 76845.69\n",
      "total_cost: 3193.35\n",
      "total_trades: 5408\n",
      "Sharpe: 0.463\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 991         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004405677 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -0.209      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.582       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    reward               | -0.06806613 |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 996          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044107963 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.03         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.53         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    reward               | 0.01488618   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.34         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1000        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005198254 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | -0.007      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.15        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    reward               | 0.4313631   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 976          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016066649 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | -0.0137      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.01         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000946    |\n",
      "|    reward               | -0.025932297 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.55         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 978          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060821157 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.0251       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.81         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    reward               | 0.088195324  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 14.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 983          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00605953   |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | -0.0224      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.35         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | -0.036433216 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 20.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 975         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002824659 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.0239      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.76        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    reward               | 1.9229423   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 17.1        |\n",
      "-----------------------------------------\n",
      "day: 1352, episode: 90\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 466715.48\n",
      "total_reward: 366715.48\n",
      "total_cost: 4470.00\n",
      "total_trades: 5408\n",
      "Sharpe: 0.895\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 969         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006290036 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.0575      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.39        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    reward               | 0.21357967  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 6.76        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 969          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050395103 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0022       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.05         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 4.2238607    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 14.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 969          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021951287 |\n",
      "|    clip_fraction        | 0.0346       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0258       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.02         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 0.04025948   |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 10.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 971          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044536674 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0166       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.88         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | 0.0013476545 |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 17.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 973          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044728625 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | -0.0525      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | 0.275499     |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 975          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033023795 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0634       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.81         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 3.1967666    |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 4.97         |\n",
      "------------------------------------------\n",
      "day: 1352, episode: 100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 188256.31\n",
      "total_reward: 88256.31\n",
      "total_cost: 3541.89\n",
      "total_trades: 5408\n",
      "Sharpe: 0.491\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 978         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006537522 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.0788      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | -0.1432553  |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 980       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0048153 |\n",
      "|    clip_fraction        | 0.0257    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.81     |\n",
      "|    explained_variance   | -0.0728   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 11.8      |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -0.00295  |\n",
      "|    reward               | 0.3010851 |\n",
      "|    std                  | 0.984     |\n",
      "|    value_loss           | 26.1      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 971          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056907395 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.0179       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.86         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | -0.063147694 |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 14.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 973         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005802328 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.034       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.19        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    reward               | -0.48502666 |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 976          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069002854 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.0144       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.17         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | -0.008863621 |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 9.93         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 978          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017659739 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.0418       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.2         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    reward               | -0.35863262  |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 29.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 979         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006415379 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | -0.0262     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.75        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    reward               | 1.0871353   |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 7.5         |\n",
      "-----------------------------------------\n",
      "day: 1352, episode: 110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 163151.00\n",
      "total_reward: 63151.00\n",
      "total_cost: 4052.34\n",
      "total_trades: 5408\n",
      "Sharpe: 0.448\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 981          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025693774 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0302       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.45         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    reward               | 0.16195066   |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 23.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 983        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00411579 |\n",
      "|    clip_fraction        | 0.0368     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.82      |\n",
      "|    explained_variance   | 0.049      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 9.16       |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.00603   |\n",
      "|    reward               | 0.1872473  |\n",
      "|    std                  | 0.993      |\n",
      "|    value_loss           | 21         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 985          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049570203 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.00969      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.59         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    reward               | 1.6241095    |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 9.25         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/td3\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 222      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 5412     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 580      |\n",
      "|    critic_loss     | 1.01e+04 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4059     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "day: 1352, episode: 120\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 5408\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 198      |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 10824    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 707      |\n",
      "|    critic_loss     | 2.9e+03  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9471     |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 189      |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 16236    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 700      |\n",
      "|    critic_loss     | 1.64e+03 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14883    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "day: 1352, episode: 130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 5408\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 186      |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 21648    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 626      |\n",
      "|    critic_loss     | 874      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20295    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 185      |\n",
      "|    time_elapsed    | 145      |\n",
      "|    total_timesteps | 27060    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 553      |\n",
      "|    critic_loss     | 605      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25707    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 186      |\n",
      "|    time_elapsed    | 174      |\n",
      "|    total_timesteps | 32472    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 488      |\n",
      "|    critic_loss     | 731      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31119    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "day: 1352, episode: 140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 5408\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 185      |\n",
      "|    time_elapsed    | 203      |\n",
      "|    total_timesteps | 37884    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 436      |\n",
      "|    critic_loss     | 732      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36531    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 184      |\n",
      "|    time_elapsed    | 234      |\n",
      "|    total_timesteps | 43296    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 394      |\n",
      "|    critic_loss     | 431      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41943    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n",
      "day: 1352, episode: 150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 100000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 5408\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 184      |\n",
      "|    time_elapsed    | 264      |\n",
      "|    total_timesteps | 48708    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 356      |\n",
      "|    critic_loss     | 327      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 47355    |\n",
      "|    reward          | 0.0      |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "#     \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=70000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-sample Performance\n",
    "Assume that the initial capital is $1,000,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading (Out-of-sample Performance)\n",
    "We update periodically in order to take full advantage of the data, e.g., retrain quarterly, monthly or weekly. We also tune the parameters along the way, in this notebook we use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends.\n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations.\n",
    "\n",
    "The Env\n",
    "https://github.com/AI4Finance-Foundation/FinRL/blob/master/finrl/meta/env_stock_trading/env_stocktrading.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_kwargs = {\n",
    "#     \"hmax\": 1, # int, maximum number of bitcoins to trade\n",
    "#     \"initial_amount\": 1000000, # start money\n",
    "#     \"num_stock_shares\": num_stock_shares,\n",
    "#     \"buy_cost_pct\": buy_cost_list, # transaction cost percentage per trade\n",
    "#     \"sell_cost_pct\": sell_cost_list, # transaction cost percentage per trade\n",
    "#     \"state_space\": state_space,\n",
    "#     \"stock_dim\": 2, # we will always have 2 stocks\n",
    "#     \"tech_indicator_list\": INDICATORS,\n",
    "#     \"action_space\": 1, # we only allow the trade to give a single action\n",
    "#     \"reward_scaling\": 1e-4 # scaling factor for reward, good for training\n",
    "# }\n",
    "\n",
    "e_trade_gym = StockTradingEnv(df = trade, risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "\n",
    "trained_a2c = A2C.load(\"trained_models/agent_a2c\") if if_using_a2c else None\n",
    "trained_ddpg = DDPG.load(\"trained_models/agent_ddpg\") if if_using_ddpg else None\n",
    "trained_ppo = PPO.load(\"trained_models/agent_ppo\") if if_using_ppo else None\n",
    "trained_td3 = TD3.load(\"trained_models/agent_td3\") if if_using_td3 else None\n",
    "trained_sac = SAC.load(\"trained_models/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_model = trained_a2c\n",
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_model = trained_ddpg\n",
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_model = trained_ppo\n",
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_model = trained_td3\n",
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trained_model = trained_sac\n",
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Backtesting Results\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ddpg            ppo\n",
      "date                                   \n",
      "2023-01-03  100000.00000  100000.000000\n",
      "2023-01-04  100041.13545  100123.004543\n",
      "2023-01-05  100028.55855  100078.868768\n",
      "2023-01-06  100081.00731  100356.935661\n",
      "2023-01-09  100284.73817  101086.509844\n"
     ]
    }
   ],
   "source": [
    "# df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "# df_result_a2c.rename(columns = {'account_value':'a2c'}, inplace = True)\n",
    "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
    "df_result_ddpg.rename(columns = {'account_value':'ddpg'}, inplace = True)\n",
    "# df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
    "# df_result_td3.rename(columns = {'account_value':'td3'}, inplace = True)\n",
    "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "df_result_ppo.rename(columns = {'account_value':'ppo'}, inplace = True)\n",
    "# df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
    "# df_result_sac.rename(columns = {'account_value':'sac'}, inplace = True)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "# result = pd.merge(result, df_result_a2c, how='outer', left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_ddpg, how='outer', left_index=True, right_index=True)\n",
    "# result = pd.merge(result, df_result_td3, how='outer', left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_ppo, how='outer', left_index=True, right_index=True)\n",
    "# result = pd.merge(result, df_result_sac, how='outer', left_index=True, right_index=True)\n",
    "print(result.head())\n",
    "# result.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\n",
    "\n",
    "# print(\"result: \", result)\n",
    "result.to_csv(RESULTS_DIR + \"/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure();\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
