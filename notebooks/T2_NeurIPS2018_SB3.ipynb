{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeurIPS2018_SB3\n",
    "\n",
    "This is a modification version based on the first notebook from [FinRL-tutorial](https://github.com/AI4Finance-Foundation/FinRL-Tutorials)\n",
    "\n",
    "https://github.com/AI4Finance-Foundation/FinRL-Tutorials/blob/master/1-Introduction/Stock_NeurIPS2018_SB3.ipynb\n",
    "\n",
    "## Part 1. Task Discription\n",
    "DRL agent training for cryptocurrency trading. \n",
    "\n",
    "This task is modeled as a Markov Decision Process (MDP), and the objective function is maximizing (expected) cumulative return.\n",
    "\n",
    "We specify the state-action-reward as follows:\n",
    "\n",
    "* **State s**: The states of the OHLCVT trading information consists of two co-moving assets (BTCUSD and BTCEUR).\n",
    "\n",
    "* **Action a**: The action space includes buying and selling. However, a certain limitation is included to operate on both assets. The pair shall never be actioned alone, it must come with a reversed direction.\n",
    "\n",
    "* **Reward function r(s, a, s′)**: Reward is an incentive for an agent to learn a better policy. For example, it can be the change of the portfolio value when taking a at state s and arriving at new state s', i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n",
    "\n",
    "**Market environment**: Cryptocurrencies from Binance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HSY/miniconda3/envs/uoa-mdt/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime, sqlite3, zipfile, os\n",
    "\n",
    "%matplotlib inline\n",
    "# from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from T2.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "check_and_make_directories([TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "Read data from `binance-public-data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2017-08-17'\n",
    "TRAIN_END_DATE = '2022-12-31'\n",
    "TRADE_START_DATE = '2023-01-01'\n",
    "TRADE_END_DATE = '2023-07-31'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This is read from SQLite database\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('../sqlite.db')\n",
    "\n",
    "table_name = 'kline_copy'\n",
    "\n",
    "# Read data from the table into a DataFrame\n",
    "query = f'SELECT * FROM {table_name};'\n",
    "sql_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Create a new DataFrame with renamed columns\n",
    "df = sql_df[['start_time', 'open', 'high', 'low', 'close', 'base_vol', 'symbol', 'id']].rename(\n",
    "    columns={\n",
    "    'start_time': 'start_time',\n",
    "    'open': 'open',\n",
    "    'high': 'high',\n",
    "    'low': 'low',\n",
    "    'close': 'close',\n",
    "    'base_vol': 'volume',\n",
    "    'symbol': 'tic',\n",
    "    'id': 'id'\n",
    "    })\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>301.13</td>\n",
       "      <td>312.18</td>\n",
       "      <td>298.00</td>\n",
       "      <td>302.00</td>\n",
       "      <td>7030.710340</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>302.00</td>\n",
       "      <td>311.79</td>\n",
       "      <td>283.94</td>\n",
       "      <td>293.96</td>\n",
       "      <td>9537.846460</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>4184.69</td>\n",
       "      <td>3850.00</td>\n",
       "      <td>4139.98</td>\n",
       "      <td>381.309763</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     open     high      low    close       volume      tic  day\n",
       "0  2017-08-17  4261.48  4485.39  4200.74  4285.08   795.150377  BTCUSDT    0\n",
       "1  2017-08-17   301.13   312.18   298.00   302.00  7030.710340  ETHUSDT    0\n",
       "2  2017-08-18  4285.08  4371.52  3938.77  4108.37  1199.888264  BTCUSDT    1\n",
       "3  2017-08-18   302.00   311.79   283.94   293.96  9537.846460  ETHUSDT    1\n",
       "4  2017-08-19  4108.37  4184.69  3850.00  4139.98   381.309763  BTCUSDT    2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of symbols to merge\n",
    "symbols = ['BTCUSDT', 'ETHUSDT']\n",
    "\n",
    "# List to store individual DataFrames\n",
    "rawdfs = []\n",
    "\n",
    "# Loop through each symbol\n",
    "for symbol in symbols:\n",
    "    directory = f'../mdt_utils/binance-public-data/python/data/spot/monthly/klines/{symbol}/1d/'\n",
    "    \n",
    "    # Loop through each zip file in the directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.zip'):\n",
    "            with zipfile.ZipFile(os.path.join(directory, file_name), 'r') as zip_ref:\n",
    "                # only one CSV file in each zip archive\n",
    "                csv_file = zip_ref.namelist()[0]\n",
    "                with zip_ref.open(csv_file) as csv_fp:\n",
    "                    # Read the CSV data into a DataFrame\n",
    "                    temp_df = pd.read_csv(csv_fp, header=None)\n",
    "                    temp_df.columns = ['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore']\n",
    "                    temp_df['date'] = pd.to_datetime(temp_df['close_time'], unit='ms').dt.strftime('%Y-%m-%d')\n",
    "                    temp_df['day'] = (pd.to_datetime(temp_df['date']) - pd.to_datetime(temp_df['date'].iloc[0])).dt.days\n",
    "                    temp_df['tic'] = symbol\n",
    "                    rawdfs.append(temp_df[['date', 'open', 'high', 'low', 'close', 'volume', 'tic', 'day']])\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "rawdf = pd.concat(rawdfs, ignore_index=True)\n",
    "\n",
    "# Count the number of unique 'tic' values per date\n",
    "tic_counts = rawdf.groupby('date')['tic'].nunique()\n",
    "\n",
    "# Filter the DataFrame to keep only rows where all 'tic' values participate\n",
    "df = rawdf[rawdf['date'].isin(tic_counts[tic_counts == len(rawdf['tic'].unique())].index)]\n",
    "\n",
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Preprocess Data\n",
    "\n",
    "TODO: The default feature engineering is based on date. I need to rewrite into timestamp based method\n",
    "\n",
    "The dafult [data split](https://github.com/AI4Finance-Foundation/FinRL/blob/master/finrl/meta/preprocessor/preprocessors.py) is not applicable here. Need to manually redo it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (1496, 8)\n",
      "Successfully added vix\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = INDICATORS,\n",
    "                    use_vix=True,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4446.630679</td>\n",
       "      <td>3946.819321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4285.080</td>\n",
       "      <td>4285.080</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>301.13</td>\n",
       "      <td>312.18</td>\n",
       "      <td>298.00</td>\n",
       "      <td>302.00</td>\n",
       "      <td>7030.710340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4446.630679</td>\n",
       "      <td>3946.819321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>302.000</td>\n",
       "      <td>302.000</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.964647</td>\n",
       "      <td>4446.630679</td>\n",
       "      <td>3946.819321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4196.725</td>\n",
       "      <td>4196.725</td>\n",
       "      <td>14.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>302.00</td>\n",
       "      <td>311.79</td>\n",
       "      <td>283.94</td>\n",
       "      <td>293.96</td>\n",
       "      <td>9537.846460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.180385</td>\n",
       "      <td>309.350277</td>\n",
       "      <td>286.609723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>297.980</td>\n",
       "      <td>297.980</td>\n",
       "      <td>14.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>4069.13</td>\n",
       "      <td>4119.62</td>\n",
       "      <td>3911.79</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>691.743060</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.655882</td>\n",
       "      <td>4325.847407</td>\n",
       "      <td>3928.440593</td>\n",
       "      <td>9.487016</td>\n",
       "      <td>-92.693236</td>\n",
       "      <td>88.718699</td>\n",
       "      <td>4127.144</td>\n",
       "      <td>4127.144</td>\n",
       "      <td>13.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      tic     open     high      low    close       volume  day  \\\n",
       "0  2017-08-17  BTCUSDT  4261.48  4485.39  4200.74  4285.08   795.150377  0.0   \n",
       "1  2017-08-17  ETHUSDT   301.13   312.18   298.00   302.00  7030.710340  0.0   \n",
       "2  2017-08-18  BTCUSDT  4285.08  4371.52  3938.77  4108.37  1199.888264  1.0   \n",
       "3  2017-08-18  ETHUSDT   302.00   311.79   283.94   293.96  9537.846460  1.0   \n",
       "4  2017-08-21  BTCUSDT  4069.13  4119.62  3911.79  4016.00   691.743060  4.0   \n",
       "\n",
       "       macd      boll_ub      boll_lb    rsi_30     cci_30       dx_30  \\\n",
       "0  0.000000  4446.630679  3946.819321  0.000000 -66.666667  100.000000   \n",
       "1  0.000000  4446.630679  3946.819321  0.000000 -66.666667  100.000000   \n",
       "2 -3.964647  4446.630679  3946.819321  0.000000 -66.666667  100.000000   \n",
       "3 -0.180385   309.350277   286.609723  0.000000 -66.666667  100.000000   \n",
       "4 -9.655882  4325.847407  3928.440593  9.487016 -92.693236   88.718699   \n",
       "\n",
       "   close_30_sma  close_60_sma    vix  \n",
       "0      4285.080      4285.080  15.55  \n",
       "1       302.000       302.000  15.55  \n",
       "2      4196.725      4196.725  14.26  \n",
       "3       297.980       297.980  14.26  \n",
       "4      4127.144      4127.144  13.19  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Build A Market Environment in OpenAI Gym-style\n",
    "The training process involves observing cryptocurrency price change, taking an action and reward's calculation. By interacting with the market environment, the agent will eventually derive a trading strategy that may maximize (expected) rewards.\n",
    "\n",
    "Our market environment, based on OpenAI Gym, simulates stock markets with historical market data.\n",
    "\n",
    "### Data Split\n",
    "We split the data into training set and testing set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data length: 2706\n",
      "Trade Data Length: 286\n",
      "Indicators: ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE, TRADE_END_DATE)\n",
    "train_length = len(train)\n",
    "trade_length = len(trade)\n",
    "print(f\"Training Data length: {train_length}\")\n",
    "print(f\"Trade Data Length: {trade_length}\")\n",
    "print(f\"Indicators: {INDICATORS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are trading with 2 assets as a pair, therefore we have only 1 pair_dimension\n",
    "\n",
    "> `1`: Represents the cash balance. There's one element in the state for the agent's cash.\n",
    ">\n",
    "> `2 * stock_dimension`: Represents the stock prices and stock ownership. There are two elements for each stock: one for the stock price and one for the number of shares owned.\n",
    ">\n",
    "> `len(INDICATORS) * stock_dimension`: Represents the technical indicators for each stock. Each indicator contributes one element per stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock Dimension: 2, State Space: 21\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "if stock_dimension != 2:\n",
    "    raise ValueError(\"Stock dimension must be equal to 2 for pair trading.\")\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 10, # int, maximum number of USDT to trade\n",
    "    \"initial_amount\": 100000, # start with 1000000 USDT\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list, # transaction cost percentage per trade\n",
    "    \"sell_cost_pct\": sell_cost_list, # transaction cost percentage per trade\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": 2, # we will always have 2 stocks\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": 2, # we only allow the trade to give a single action\n",
    "    \"reward_scaling\": 1e-4 # scaling factor for reward, good for training\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100000,\n",
       " 4285.08,\n",
       " 302.0,\n",
       " 0,\n",
       " 0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4446.630678606951,\n",
       " 4446.630678606951,\n",
       " 3946.81932139305,\n",
       " 3946.81932139305,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -66.666666666667,\n",
       " -66.666666666667,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 4285.08,\n",
       " 302.0,\n",
       " 4285.08,\n",
       " 302.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of state\n",
    "# 94502.19235000112: This is the available cash balance that the agent has for making trading decisions.\n",
    "# 24948.21: The price of the first stock in your trading pair (e.g., BTC-GBP).\n",
    "# 21668.05: The price of the second stock in your trading pair (e.g., BTC-EUR).\n",
    "# 103: The number of shares the agent holds for the first stock (e.g., BTC-GBP).\n",
    "# 0: The number of shares the agent holds for the second stock (e.g., BTC-EUR).\n",
    "# -299.9631790789099: A technical indicator value.\n",
    "# -345.112034646816: A technical indicator value.\n",
    "# 26817.756609157783: A technical indicator value.\n",
    "# 23644.528099789444: A technical indicator value.\n",
    "# 24186.333390842214: A technical indicator value.\n",
    "# 20930.97290021056: A technical indicator value.\n",
    "# 48.63796032144048: A technical indicator value.\n",
    "# 47.40677058214158: A technical indicator value.\n",
    "# -74.29641721884254: A technical indicator value.\n",
    "# -89.66529346827706: A technical indicator value.\n",
    "# 12.572876815282788: A technical indicator value.\n",
    "# 16.60796108870377: A technical indicator value.\n",
    "# 25597.621333333333: A technical indicator value.\n",
    "# 22452.637666666666: A technical indicator value.\n",
    "# 25993.954166666666: A technical indicator value.\n",
    "# 22842.914500000003: A technical indicator value.\n",
    "\n",
    "e_train_gym.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4485.39</td>\n",
       "      <td>4200.74</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>795.150377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4446.630679</td>\n",
       "      <td>3946.819321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4285.080000</td>\n",
       "      <td>4285.080000</td>\n",
       "      <td>15.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>301.13</td>\n",
       "      <td>312.18</td>\n",
       "      <td>298.00</td>\n",
       "      <td>302.00</td>\n",
       "      <td>7030.710340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4446.630679</td>\n",
       "      <td>3946.819321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>15.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>4285.08</td>\n",
       "      <td>4371.52</td>\n",
       "      <td>3938.77</td>\n",
       "      <td>4108.37</td>\n",
       "      <td>1199.888264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.964647</td>\n",
       "      <td>4446.630679</td>\n",
       "      <td>3946.819321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4196.725000</td>\n",
       "      <td>4196.725000</td>\n",
       "      <td>14.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>302.00</td>\n",
       "      <td>311.79</td>\n",
       "      <td>283.94</td>\n",
       "      <td>293.96</td>\n",
       "      <td>9537.846460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.180385</td>\n",
       "      <td>309.350277</td>\n",
       "      <td>286.609723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>297.980000</td>\n",
       "      <td>297.980000</td>\n",
       "      <td>14.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>4069.13</td>\n",
       "      <td>4119.62</td>\n",
       "      <td>3911.79</td>\n",
       "      <td>4016.00</td>\n",
       "      <td>691.743060</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.655882</td>\n",
       "      <td>4325.847407</td>\n",
       "      <td>3928.440593</td>\n",
       "      <td>9.487016</td>\n",
       "      <td>-92.693236</td>\n",
       "      <td>88.718699</td>\n",
       "      <td>4127.144000</td>\n",
       "      <td>4127.144000</td>\n",
       "      <td>13.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1211.55</td>\n",
       "      <td>1215.78</td>\n",
       "      <td>1181.06</td>\n",
       "      <td>1190.15</td>\n",
       "      <td>367828.891400</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-13.556833</td>\n",
       "      <td>1317.115002</td>\n",
       "      <td>1143.339998</td>\n",
       "      <td>45.345868</td>\n",
       "      <td>-87.159035</td>\n",
       "      <td>31.922068</td>\n",
       "      <td>1241.650333</td>\n",
       "      <td>1280.678833</td>\n",
       "      <td>22.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>16547.32</td>\n",
       "      <td>16664.41</td>\n",
       "      <td>16488.91</td>\n",
       "      <td>16633.47</td>\n",
       "      <td>160998.471580</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-125.739003</td>\n",
       "      <td>17667.869492</td>\n",
       "      <td>16205.851508</td>\n",
       "      <td>44.562902</td>\n",
       "      <td>-116.527071</td>\n",
       "      <td>20.622563</td>\n",
       "      <td>16973.549000</td>\n",
       "      <td>17343.340833</td>\n",
       "      <td>21.440001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1190.15</td>\n",
       "      <td>1206.57</td>\n",
       "      <td>1186.77</td>\n",
       "      <td>1200.49</td>\n",
       "      <td>249130.486900</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-13.782247</td>\n",
       "      <td>1313.507949</td>\n",
       "      <td>1140.686051</td>\n",
       "      <td>46.000465</td>\n",
       "      <td>-82.365815</td>\n",
       "      <td>31.922068</td>\n",
       "      <td>1241.117000</td>\n",
       "      <td>1274.179667</td>\n",
       "      <td>21.440001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>16633.47</td>\n",
       "      <td>16677.35</td>\n",
       "      <td>16333.00</td>\n",
       "      <td>16607.48</td>\n",
       "      <td>164916.311740</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-130.253397</td>\n",
       "      <td>17650.263541</td>\n",
       "      <td>16171.456459</td>\n",
       "      <td>44.405086</td>\n",
       "      <td>-122.471176</td>\n",
       "      <td>25.159441</td>\n",
       "      <td>16955.010333</td>\n",
       "      <td>17278.619833</td>\n",
       "      <td>21.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>ETHUSDT</td>\n",
       "      <td>1200.48</td>\n",
       "      <td>1202.15</td>\n",
       "      <td>1181.08</td>\n",
       "      <td>1199.99</td>\n",
       "      <td>266014.211500</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-13.841678</td>\n",
       "      <td>1308.930700</td>\n",
       "      <td>1138.627300</td>\n",
       "      <td>45.972921</td>\n",
       "      <td>-82.887202</td>\n",
       "      <td>33.322977</td>\n",
       "      <td>1237.968000</td>\n",
       "      <td>1267.968000</td>\n",
       "      <td>21.670000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2706 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      tic      open      high       low     close  \\\n",
       "0     2017-08-17  BTCUSDT   4261.48   4485.39   4200.74   4285.08   \n",
       "0     2017-08-17  ETHUSDT    301.13    312.18    298.00    302.00   \n",
       "1     2017-08-18  BTCUSDT   4285.08   4371.52   3938.77   4108.37   \n",
       "1     2017-08-18  ETHUSDT    302.00    311.79    283.94    293.96   \n",
       "2     2017-08-21  BTCUSDT   4069.13   4119.62   3911.79   4016.00   \n",
       "...          ...      ...       ...       ...       ...       ...   \n",
       "1350  2022-12-28  ETHUSDT   1211.55   1215.78   1181.06   1190.15   \n",
       "1351  2022-12-29  BTCUSDT  16547.32  16664.41  16488.91  16633.47   \n",
       "1351  2022-12-29  ETHUSDT   1190.15   1206.57   1186.77   1200.49   \n",
       "1352  2022-12-30  BTCUSDT  16633.47  16677.35  16333.00  16607.48   \n",
       "1352  2022-12-30  ETHUSDT   1200.48   1202.15   1181.08   1199.99   \n",
       "\n",
       "             volume   day        macd       boll_ub       boll_lb     rsi_30  \\\n",
       "0        795.150377   0.0    0.000000   4446.630679   3946.819321   0.000000   \n",
       "0       7030.710340   0.0    0.000000   4446.630679   3946.819321   0.000000   \n",
       "1       1199.888264   1.0   -3.964647   4446.630679   3946.819321   0.000000   \n",
       "1       9537.846460   1.0   -0.180385    309.350277    286.609723   0.000000   \n",
       "2        691.743060   4.0   -9.655882   4325.847407   3928.440593   9.487016   \n",
       "...             ...   ...         ...           ...           ...        ...   \n",
       "1350  367828.891400  27.0  -13.556833   1317.115002   1143.339998  45.345868   \n",
       "1351  160998.471580  28.0 -125.739003  17667.869492  16205.851508  44.562902   \n",
       "1351  249130.486900  28.0  -13.782247   1313.507949   1140.686051  46.000465   \n",
       "1352  164916.311740  29.0 -130.253397  17650.263541  16171.456459  44.405086   \n",
       "1352  266014.211500  29.0  -13.841678   1308.930700   1138.627300  45.972921   \n",
       "\n",
       "          cci_30       dx_30  close_30_sma  close_60_sma        vix  \n",
       "0     -66.666667  100.000000   4285.080000   4285.080000  15.550000  \n",
       "0     -66.666667  100.000000    302.000000    302.000000  15.550000  \n",
       "1     -66.666667  100.000000   4196.725000   4196.725000  14.260000  \n",
       "1     -66.666667  100.000000    297.980000    297.980000  14.260000  \n",
       "2     -92.693236   88.718699   4127.144000   4127.144000  13.190000  \n",
       "...          ...         ...           ...           ...        ...  \n",
       "1350  -87.159035   31.922068   1241.650333   1280.678833  22.139999  \n",
       "1351 -116.527071   20.622563  16973.549000  17343.340833  21.440001  \n",
       "1351  -82.365815   31.922068   1241.117000   1274.179667  21.440001  \n",
       "1352 -122.471176   25.159441  16955.010333  17278.619833  21.670000  \n",
       "1352  -82.887202   33.322977   1237.968000   1267.968000  21.670000  \n",
       "\n",
       "[2706 rows x 17 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6. Train DRL Agents\n",
    "* The DRL algorithms are from Stable Baselines 3. Users are also encouraged to try ElegantRL and Ray RLlib.\n",
    "* FinRL includes fine-tuned standard DRL algorithms, such as DQN, DDPG, Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to results/a2c\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1016      |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.8      |\n",
      "|    explained_variance | -0.19     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -6.28     |\n",
      "|    reward             | 1.3217335 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 6.36      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1075       |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 0          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.83      |\n",
      "|    explained_variance | 0.134      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -18.8      |\n",
      "|    reward             | -6.5194263 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 36.7       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 1126         |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.84        |\n",
      "|    explained_variance | -0.607       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | 0.0192       |\n",
      "|    reward             | -0.034646332 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.00217      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1159        |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.85       |\n",
      "|    explained_variance | -2.17       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 2.86        |\n",
      "|    reward             | -0.54989815 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1156       |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.83      |\n",
      "|    explained_variance | -0.215     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -11.4      |\n",
      "|    reward             | -2.9175587 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 47.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1165       |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.84      |\n",
      "|    explained_variance | 0.337      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -0.169     |\n",
      "|    reward             | 0.15207455 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.00901    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1180        |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.83       |\n",
      "|    explained_variance | 0.509       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 1.28        |\n",
      "|    reward             | 0.108039215 |\n",
      "|    std                | 0.994       |\n",
      "|    value_loss         | 0.257       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1175       |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.81      |\n",
      "|    explained_variance | -0.0357    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 0.0226     |\n",
      "|    reward             | 0.16821457 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 0.0333     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1193        |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.82       |\n",
      "|    explained_variance | -0.0603     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.411       |\n",
      "|    reward             | 0.017926443 |\n",
      "|    std                | 0.993       |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1210        |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.84       |\n",
      "|    explained_variance | 0.00148     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -23         |\n",
      "|    reward             | -0.25706428 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 133         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1223      |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.83     |\n",
      "|    explained_variance | -0.0715   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -8.11     |\n",
      "|    reward             | 1.0622959 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 8.35      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1235       |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.83      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 0.344      |\n",
      "|    reward             | -0.6275147 |\n",
      "|    std                | 0.995      |\n",
      "|    value_loss         | 0.0276     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1231       |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.82      |\n",
      "|    explained_variance | 0.033      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 8.19       |\n",
      "|    reward             | 0.53659385 |\n",
      "|    std                | 0.992      |\n",
      "|    value_loss         | 17.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1240       |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | -0.0754    |\n",
      "|    reward             | 0.01701508 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 0.0543     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1249        |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.85       |\n",
      "|    explained_variance | -0.296      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.645       |\n",
      "|    reward             | -0.38745537 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.0706      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1257        |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.84       |\n",
      "|    explained_variance | 0.0377      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | -1.6        |\n",
      "|    reward             | -0.15989311 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1260        |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.83       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.0534     |\n",
      "|    reward             | 0.006176276 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.000777    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1267       |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.85      |\n",
      "|    explained_variance | -0.146     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 0.229      |\n",
      "|    reward             | 0.04120474 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.284      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1272       |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -0.984     |\n",
      "|    reward             | 0.00853896 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.193      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1278       |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.83      |\n",
      "|    explained_variance | 0.661      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 0.623      |\n",
      "|    reward             | 0.06588501 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.0213     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1282     |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.86    |\n",
      "|    explained_variance | -0.079   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 2.46     |\n",
      "|    reward             | 4.42966  |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.33     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1286       |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -4.62      |\n",
      "|    reward             | 0.21151404 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.56       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1290      |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.84     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -0.308    |\n",
      "|    reward             | -0.2396   |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.0421    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1294       |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.83      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | 0.145      |\n",
      "|    reward             | 0.45150915 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 0.00424    |\n",
      "--------------------------------------\n",
      "day: 1352, episode: 10\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 55528.77\n",
      "total_reward: -44471.23\n",
      "total_cost: -653502.22\n",
      "total_trades: 5408\n",
      "Sharpe: 0.446\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1295        |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.83       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | 1.64        |\n",
      "|    reward             | -0.37413916 |\n",
      "|    std                | 0.995       |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1298       |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.83      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | -1.89      |\n",
      "|    reward             | 0.36229268 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 0.76       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1299       |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | 4.43       |\n",
      "|    reward             | 0.02140445 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 7.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1293       |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.85      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -2.89      |\n",
      "|    reward             | 0.01510014 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1296       |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.84      |\n",
      "|    explained_variance | 0.118      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | 5.79       |\n",
      "|    reward             | 0.22133166 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 5.78       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1298      |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.85     |\n",
      "|    explained_variance | -3.07     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -0.651    |\n",
      "|    reward             | 1.9685321 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.0623    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1301       |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.86      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 0.7        |\n",
      "|    reward             | 0.19837284 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.0723     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1303       |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.86      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | 2.25       |\n",
      "|    reward             | -0.1513286 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.19       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1306       |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -1.07      |\n",
      "|    reward             | 0.68849623 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.252      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1308        |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.88       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 0.582       |\n",
      "|    reward             | -0.07649236 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1310        |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | 1.98        |\n",
      "|    reward             | -0.10548768 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 1.07        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1311       |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -0.508     |\n",
      "|    reward             | -0.2119302 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.0252     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1308      |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.9      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 12.2      |\n",
      "|    reward             | 0.2550722 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 26.3      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1309        |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.89       |\n",
      "|    explained_variance | 0.099       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -0.573      |\n",
      "|    reward             | -0.21070383 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.0985      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1311       |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | -1.34      |\n",
      "|    reward             | 0.11305576 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.365      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1313      |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.93     |\n",
      "|    explained_variance | 0.242     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -0.521    |\n",
      "|    reward             | -0.548985 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1         |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1314       |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | -0.216     |\n",
      "|    reward             | 0.04081676 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.00764    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1315        |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | -2.1        |\n",
      "|    reward             | -0.12236536 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.553       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1317      |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.95     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 0.781     |\n",
      "|    reward             | 2.122414  |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.413     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 1319          |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -2.97         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | -0.293        |\n",
      "|    reward             | -0.0008187131 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 0.0379        |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1314      |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -7.34     |\n",
      "|    reward             | -2.684032 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 9.53      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1315       |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.98      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | -0.00535   |\n",
      "|    reward             | 0.09252388 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.114      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1316      |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.97     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -2.91     |\n",
      "|    reward             | 0.5489543 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.34      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1317        |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.98       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -13.2       |\n",
      "|    reward             | -0.01524657 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 21.1        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1318      |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.97     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 3.59      |\n",
      "|    reward             | -0.30696  |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.93      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1319      |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.98     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -0.608    |\n",
      "|    reward             | -0.7594   |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.0636    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1320       |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.98      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -6.15      |\n",
      "|    reward             | -0.6235773 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 3.8        |\n",
      "--------------------------------------\n",
      "day: 1352, episode: 20\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 863532.30\n",
      "total_reward: 763532.30\n",
      "total_cost: -881780.28\n",
      "total_trades: 5408\n",
      "Sharpe: 0.466\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1321     |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.192   |\n",
      "|    reward             | 0.02024  |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.00795  |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1323       |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | 0.44       |\n",
      "|    reward             | -0.5084324 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.05       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1324       |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | 0.123      |\n",
      "|    reward             | 0.27822304 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.0337     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1325       |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | -5.08      |\n",
      "|    reward             | 0.00201816 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 3.04       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1326       |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -0.0546    |\n",
      "|    reward             | 0.15887529 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 3.86       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1327      |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.03     |\n",
      "|    explained_variance | 0.0251    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 2.66      |\n",
      "|    reward             | 0.0274792 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.808     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1328       |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | 0.387      |\n",
      "|    reward             | 0.01813991 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.0316     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1328      |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.06     |\n",
      "|    explained_variance | -0.0555   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 6.02      |\n",
      "|    reward             | 0.6451982 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 10.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1329      |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -2.06     |\n",
      "|    reward             | -1.942756 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.752     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1330        |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.05       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | 0.379       |\n",
      "|    reward             | -0.23535931 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.0287      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1330        |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | -8.18       |\n",
      "|    reward             | -0.27303052 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 6.01        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1331     |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.0378   |\n",
      "|    reward             | 0.149928 |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 0.000525 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1332      |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -8.73     |\n",
      "|    reward             | 0.7755888 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 27.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1333       |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | -1.23      |\n",
      "|    reward             | -0.2951206 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.252      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1334     |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 0.353    |\n",
      "|    reward             | 1.247919 |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 0.0278   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1330      |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.05     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 10.2      |\n",
      "|    reward             | 0.6287913 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 14.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1330       |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | -2.1       |\n",
      "|    reward             | -0.2949986 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.622      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1330       |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.07      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | 0.774      |\n",
      "|    reward             | 0.00731956 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.133      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1331      |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 14        |\n",
      "|    reward             | -0.566591 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 28.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1332      |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 3.78      |\n",
      "|    reward             | 0.0024388 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.39      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1333        |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.1        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -1.85       |\n",
      "|    reward             | -0.01965343 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1333       |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.09      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 18.9       |\n",
      "|    reward             | 0.28976494 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 20.9       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1334     |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -5.44    |\n",
      "|    reward             | 1.813213 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 2.83     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1335       |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | 4.08       |\n",
      "|    reward             | -0.8503077 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 2.84       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1335       |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | 0.49       |\n",
      "|    reward             | 0.38838807 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.0901     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1336        |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.13       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | -0.17447388 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1336        |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | -0.0275     |\n",
      "|    reward             | -0.06925876 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.499       |\n",
      "---------------------------------------\n",
      "day: 1352, episode: 30\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 967865.06\n",
      "total_reward: 867865.06\n",
      "total_cost: -1031993.93\n",
      "total_trades: 5408\n",
      "Sharpe: -0.327\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1336        |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | -1.48       |\n",
      "|    reward             | -0.31980515 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.235       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1336        |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | 1.54        |\n",
      "|    reward             | -0.15120848 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1337       |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | 2.38       |\n",
      "|    reward             | 0.24715649 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.826      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1337        |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.14       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | -0.387      |\n",
      "|    reward             | -0.08669536 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.0246      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1338       |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 31         |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.15      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 14         |\n",
      "|    reward             | 0.24100628 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 28.8       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1338        |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.15       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -2.13       |\n",
      "|    reward             | -0.07607952 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.492       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1339        |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.16       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | -3.33       |\n",
      "|    reward             | -0.12481356 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1340       |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.17      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 3.79       |\n",
      "|    reward             | -1.9287963 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 7.46       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1340       |\n",
      "|    iterations         | 8700       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 43500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.19      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8699       |\n",
      "|    policy_loss        | -0.0456    |\n",
      "|    reward             | 0.76185375 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 0.00248    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1340       |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | -0.584     |\n",
      "|    reward             | 0.20705624 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 0.0979     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1341       |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.2       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | 3.09       |\n",
      "|    reward             | -3.0567207 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 1.26       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1340      |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -0.201    |\n",
      "|    reward             | 0.3966366 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 0.0157    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1339       |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.24      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | -11.7      |\n",
      "|    reward             | -1.8328651 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 12.2       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1339        |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.23       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | -0.01997076 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 0.376       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1339       |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 34         |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.24      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -6.25      |\n",
      "|    reward             | 0.53142995 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 3.14       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1335       |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 35         |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.24      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -9.31      |\n",
      "|    reward             | -0.9803873 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 17.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 1336       |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 35         |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.25      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | 5.76       |\n",
      "|    reward             | 0.01394392 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 2.22       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1336     |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.561   |\n",
      "|    reward             | 3.166258 |\n",
      "|    std                | 1.23     |\n",
      "|    value_loss         | 0.06     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1337      |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.25     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -15.9     |\n",
      "|    reward             | 1.3172547 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 17.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1337        |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.25       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -0.242      |\n",
      "|    reward             | -0.42929795 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 0.00911     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 1337        |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.26       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 0.829       |\n",
      "|    reward             | -0.08136772 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 0.0495      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1338      |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -0.644    |\n",
      "|    reward             | 0.2609113 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.129     |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1352, episode: 40\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: -317930161.52\n",
      "total_reward: -318030161.52\n",
      "total_cost: -526138.80\n",
      "total_trades: 5408\n",
      "Sharpe: 0.450\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 297       |\n",
      "|    time_elapsed    | 18        |\n",
      "|    total_timesteps | 5412      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.72e+05 |\n",
      "|    critic_loss     | 3.29e+10  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 4059      |\n",
      "|    reward          | 35.22919  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 258       |\n",
      "|    time_elapsed    | 41        |\n",
      "|    total_timesteps | 10824     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.99e+05 |\n",
      "|    critic_loss     | 1.94e+09  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9471      |\n",
      "|    reward          | 35.22919  |\n",
      "----------------------------------\n",
      "day: 1352, episode: 50\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: -317930161.52\n",
      "total_reward: -318030161.52\n",
      "total_cost: -526138.80\n",
      "total_trades: 5408\n",
      "Sharpe: 0.450\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 257       |\n",
      "|    time_elapsed    | 63        |\n",
      "|    total_timesteps | 16236     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.58e+05 |\n",
      "|    critic_loss     | 5.38e+08  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 14883     |\n",
      "|    reward          | 35.22919  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 254       |\n",
      "|    time_elapsed    | 84        |\n",
      "|    total_timesteps | 21648     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.68e+05 |\n",
      "|    critic_loss     | 2.77e+08  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 20295     |\n",
      "|    reward          | 35.22919  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 253       |\n",
      "|    time_elapsed    | 106       |\n",
      "|    total_timesteps | 27060     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.22e+05 |\n",
      "|    critic_loss     | 1.43e+08  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 25707     |\n",
      "|    reward          | 35.22919  |\n",
      "----------------------------------\n",
      "day: 1352, episode: 60\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: -317930161.52\n",
      "total_reward: -318030161.52\n",
      "total_cost: -526138.80\n",
      "total_trades: 5408\n",
      "Sharpe: 0.450\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 250       |\n",
      "|    time_elapsed    | 129       |\n",
      "|    total_timesteps | 32472     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -8.91e+04 |\n",
      "|    critic_loss     | 8.17e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 31119     |\n",
      "|    reward          | 35.22919  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 251       |\n",
      "|    time_elapsed    | 150       |\n",
      "|    total_timesteps | 37884     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.67e+04 |\n",
      "|    critic_loss     | 6.67e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 36531     |\n",
      "|    reward          | 35.22919  |\n",
      "----------------------------------\n",
      "day: 1352, episode: 70\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: -317930161.52\n",
      "total_reward: -318030161.52\n",
      "total_cost: -526138.80\n",
      "total_trades: 5408\n",
      "Sharpe: 0.450\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 253       |\n",
      "|    time_elapsed    | 171       |\n",
      "|    total_timesteps | 43296     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.77e+04 |\n",
      "|    critic_loss     | 5.14e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 41943     |\n",
      "|    reward          | 35.22919  |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 253       |\n",
      "|    time_elapsed    | 192       |\n",
      "|    total_timesteps | 48708     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.73e+04 |\n",
      "|    critic_loss     | 3.35e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 47355     |\n",
      "|    reward          | 35.22919  |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 1754       |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 1          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.06866107 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1679        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005470558 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -0.0304     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | 0.01854804  |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 25.1        |\n",
      "-----------------------------------------\n",
      "day: 1352, episode: 80\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 207624.95\n",
      "total_reward: 107624.95\n",
      "total_cost: -249280.95\n",
      "total_trades: 5408\n",
      "Sharpe: -0.439\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1639        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006330521 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | -0.000689   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | -0.06656432 |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 88.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1608        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001588734 |\n",
      "|    clip_fraction        | 0.0252      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | 0.000395    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.77        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    reward               | -0.9094081  |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 13.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1611        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004325164 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | -0.0178     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    reward               | 0.04159705  |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067078657 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 0.015        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | -0.04227296  |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 37.8         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1576          |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 9             |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.006088225   |\n",
      "|    clip_fraction        | 0.049         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.81         |\n",
      "|    explained_variance   | 0.0166        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 8.46          |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.00414      |\n",
      "|    reward               | -0.0020898648 |\n",
      "|    std                  | 0.986         |\n",
      "|    value_loss           | 27.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062254258 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.00667      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.44         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    reward               | -0.016431844 |\n",
      "|    std                  | 0.98         |\n",
      "|    value_loss           | 9.24         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043617226 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 0.0084       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    reward               | -1.1579244   |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 33           |\n",
      "------------------------------------------\n",
      "day: 1352, episode: 90\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 914014.26\n",
      "total_reward: 814014.26\n",
      "total_cost: -161363.04\n",
      "total_trades: 5408\n",
      "Sharpe: 0.441\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005994305  |\n",
      "|    clip_fraction        | 0.0848       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.8         |\n",
      "|    explained_variance   | 5.81e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.91         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    reward               | -0.008283278 |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006039748 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.0372      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    reward               | -0.20003769 |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045813806 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.0655       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.8          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    reward               | -0.002526484 |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 24.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1591        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006783292 |\n",
      "|    clip_fraction        | 0.0622      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.0692      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.06        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    reward               | -2.2109504  |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050240075 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.00141      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    reward               | -0.16522342  |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 282          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071550817 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0292       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    reward               | -5.922058    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "day: 1352, episode: 100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: -2563.00\n",
      "total_reward: -102563.00\n",
      "total_cost: -404454.09\n",
      "total_trades: 5408\n",
      "Sharpe: 0.440\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067935633 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0114       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.7         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | 0.00797407   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 39.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036222422 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0233       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | -1.4404818   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 44.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044554407 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.048        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    reward               | 0.31396002   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 26.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006833803 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.0199      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.83        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    reward               | 5.352965    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054499647 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.0172       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 50.4         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | 0.0010267064 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 60.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005356252 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | 0.0283      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | -0.02364768 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 54.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006155161 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.045       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    reward               | 0.6160832   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "day: 1352, episode: 110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 311506.57\n",
      "total_reward: 211506.57\n",
      "total_cost: -201346.45\n",
      "total_trades: 5408\n",
      "Sharpe: -0.423\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007729709  |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.00748      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.98         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    reward               | -0.074527584 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 9.25         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00811797  |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.0466      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    reward               | -0.12070241 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055369753 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | 0.00892      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.26         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 0.4659475    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 8.14         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/td3\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 320        |\n",
      "|    time_elapsed    | 16         |\n",
      "|    total_timesteps | 5412       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -1.19e+03  |\n",
      "|    critic_loss     | 5.4e+05    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 4059       |\n",
      "|    reward          | 0.09252388 |\n",
      "-----------------------------------\n",
      "day: 1352, episode: 120\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 1029010.74\n",
      "total_reward: 929010.74\n",
      "total_cost: -1052234.74\n",
      "total_trades: 5408\n",
      "Sharpe: -0.524\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 283        |\n",
      "|    time_elapsed    | 38         |\n",
      "|    total_timesteps | 10824      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -831       |\n",
      "|    critic_loss     | 3.3e+04    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 9471       |\n",
      "|    reward          | 0.09252388 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 274        |\n",
      "|    time_elapsed    | 59         |\n",
      "|    total_timesteps | 16236      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -757       |\n",
      "|    critic_loss     | 8.94e+03   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 14883      |\n",
      "|    reward          | 0.09252388 |\n",
      "-----------------------------------\n",
      "day: 1352, episode: 130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 1029010.74\n",
      "total_reward: 929010.74\n",
      "total_cost: -1052234.74\n",
      "total_trades: 5408\n",
      "Sharpe: -0.524\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 269        |\n",
      "|    time_elapsed    | 80         |\n",
      "|    total_timesteps | 21648      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -597       |\n",
      "|    critic_loss     | 7.06e+03   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 20295      |\n",
      "|    reward          | 0.09252388 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 20         |\n",
      "|    fps             | 267        |\n",
      "|    time_elapsed    | 101        |\n",
      "|    total_timesteps | 27060      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -425       |\n",
      "|    critic_loss     | 2.42e+03   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 25707      |\n",
      "|    reward          | 0.09252388 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 24         |\n",
      "|    fps             | 264        |\n",
      "|    time_elapsed    | 122        |\n",
      "|    total_timesteps | 32472      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -358       |\n",
      "|    critic_loss     | 972        |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 31119      |\n",
      "|    reward          | 0.09252388 |\n",
      "-----------------------------------\n",
      "day: 1352, episode: 140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 1029010.74\n",
      "total_reward: 929010.74\n",
      "total_cost: -1052234.74\n",
      "total_trades: 5408\n",
      "Sharpe: -0.524\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 260        |\n",
      "|    time_elapsed    | 145        |\n",
      "|    total_timesteps | 37884      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -257       |\n",
      "|    critic_loss     | 273        |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 36531      |\n",
      "|    reward          | 0.09252388 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 32         |\n",
      "|    fps             | 261        |\n",
      "|    time_elapsed    | 165        |\n",
      "|    total_timesteps | 43296      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -215       |\n",
      "|    critic_loss     | 168        |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 41943      |\n",
      "|    reward          | 0.09252388 |\n",
      "-----------------------------------\n",
      "day: 1352, episode: 150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 1029010.74\n",
      "total_reward: 929010.74\n",
      "total_cost: -1052234.74\n",
      "total_trades: 5408\n",
      "Sharpe: -0.524\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 36         |\n",
      "|    fps             | 259        |\n",
      "|    time_elapsed    | 187        |\n",
      "|    total_timesteps | 48708      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -179       |\n",
      "|    critic_loss     | 105        |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 47355      |\n",
      "|    reward          | 0.09252388 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "#     \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=70000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-sample Performance\n",
    "Assume that the initial capital is $1,000,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading (Out-of-sample Performance)\n",
    "We update periodically in order to take full advantage of the data, e.g., retrain quarterly, monthly or weekly. We also tune the parameters along the way, in this notebook we use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends.\n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations.\n",
    "\n",
    "The Env\n",
    "https://github.com/AI4Finance-Foundation/FinRL/blob/master/finrl/meta/env_stock_trading/env_stocktrading.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_kwargs = {\n",
    "#     \"hmax\": 1, # int, maximum number of bitcoins to trade\n",
    "#     \"initial_amount\": 1000000, # start money\n",
    "#     \"num_stock_shares\": num_stock_shares,\n",
    "#     \"buy_cost_pct\": buy_cost_list, # transaction cost percentage per trade\n",
    "#     \"sell_cost_pct\": sell_cost_list, # transaction cost percentage per trade\n",
    "#     \"state_space\": state_space,\n",
    "#     \"stock_dim\": 2, # we will always have 2 stocks\n",
    "#     \"tech_indicator_list\": INDICATORS,\n",
    "#     \"action_space\": 1, # we only allow the trade to give a single action\n",
    "#     \"reward_scaling\": 1e-4 # scaling factor for reward, good for training\n",
    "# }\n",
    "\n",
    "e_trade_gym = StockTradingEnv(df = trade, risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "\n",
    "trained_a2c = A2C.load(\"trained_models/agent_a2c\") if if_using_a2c else None\n",
    "trained_ddpg = DDPG.load(\"trained_models/agent_ddpg\") if if_using_ddpg else None\n",
    "trained_ppo = PPO.load(\"trained_models/agent_ppo\") if if_using_ppo else None\n",
    "trained_td3 = TD3.load(\"trained_models/agent_td3\") if if_using_td3 else None\n",
    "trained_sac = SAC.load(\"trained_models/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_model = trained_a2c\n",
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_model = trained_ddpg\n",
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_model = trained_ppo\n",
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_model = trained_td3\n",
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trained_model = trained_sac\n",
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_model, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Backtesting Results\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    a2c          td3            ppo\n",
      "date                                               \n",
      "2023-01-03  100000.0000  100000.0000  100000.000000\n",
      "2023-01-04   98748.4554   98748.4554  100492.235733\n",
      "2023-01-05   99607.5698   99607.5698  100444.112096\n",
      "2023-01-06   99092.8438   99092.8438  100761.098403\n",
      "2023-01-09   97494.7698   97494.7698  101307.451430\n"
     ]
    }
   ],
   "source": [
    "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "df_result_a2c.rename(columns = {'account_value':'a2c'}, inplace = True)\n",
    "# df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
    "# df_result_ddpg.rename(columns = {'account_value':'ddpg'}, inplace = True)\n",
    "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
    "df_result_td3.rename(columns = {'account_value':'td3'}, inplace = True)\n",
    "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "df_result_ppo.rename(columns = {'account_value':'ppo'}, inplace = True)\n",
    "# df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
    "# df_result_sac.rename(columns = {'account_value':'sac'}, inplace = True)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result = pd.merge(result, df_result_a2c, how='outer', left_index=True, right_index=True)\n",
    "# result = pd.merge(result, df_result_ddpg, how='outer', left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_td3, how='outer', left_index=True, right_index=True)\n",
    "result = pd.merge(result, df_result_ppo, how='outer', left_index=True, right_index=True)\n",
    "# result = pd.merge(result, df_result_sac, how='outer', left_index=True, right_index=True)\n",
    "print(result.head())\n",
    "# result.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']\n",
    "\n",
    "# print(\"result: \", result)\n",
    "result.to_csv(RESULTS_DIR + \"/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure();\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
